Text summarization has developed into a crucial research area to automatically extract the most important information from lengthy documents as a result of the explosive growth of digital content. Transformer models have made significant progress in text summarization tasks because of their capacity to capture context and long-range dependencies. In this paper, a comparative analysis of different transformer models for abstractive legal document summarization, such as Legal LED, BART, T5, and Pegasus. We assess the performance of these models using a variety of evaluation metrics, including ROUGE score and Cosine similarity, and we compare them to different transformer models. The experiments show that Bart model outperforms other models on most of the evaluation metrics and can generate high-quality summaries with a reasonable length. This study can offer valuable guidance to researchers and practitioners who are looking to select an appropriate transformer-based model for text summarization tasks.

![legal](https://github.com/user-attachments/assets/5010ac62-8639-4de0-a9af-39cc8c70c880)

The proposed approach is implemented using various transformers models such as Bart, Pegasus, T5 and Legal Led and obtained results using different evaluation metrics. Based on the results obtained, a comparative analysis on different transformers models is performed on both the datasets in this research.

![bart](https://github.com/user-attachments/assets/0078db76-9e42-4f6b-b258-c94d762b52a1)

A GUI is setup for the summarization task where all the models are given as an option and after giving an input, if the user clicks on the model, the summary will get generated by respective model in the GUI. This summary generated by the model is compared with the already available target summaries in the dataset and evaluated.
