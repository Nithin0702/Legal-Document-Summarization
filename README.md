Text summarization has developed into a crucial research area to automatically extract the most important information from lengthy documents as a result of the explosive growth of digital content. Transformer models have made significant progress in text summarization tasks because of their capacity to capture context and long-range dependencies. In this paper, a comparative analysis of different transformer models for abstractive legal document summarization, such as Legal LED, BART, T5, and Pegasus. We assess the performance of these models using a variety of evaluation metrics, including ROUGE score and Cosine similarity, and we compare them to different transformer models. The experiments show that Bart model outperforms other models on most of the evaluation metrics and can generate high-quality summaries with a reasonable length. This study can offer valuable guidance to researchers and practitioners who are looking to select an appropriate transformer-based model for text summarization tasks.
